#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ•°æ®é›†ç»Ÿè®¡åˆ†æè„šæœ¬
åˆ†æè®­ç»ƒé›†å’Œæµ‹è¯•é›†çš„åœºæ™¯åˆ†å¸ƒã€è½¨è¿¹æ•°é‡ç­‰ç»Ÿè®¡ä¿¡æ¯
"""

import pandas as pd
import numpy as np
from collections import Counter, defaultdict
import os

def analyze_dataset_statistics():
    """åˆ†ææ•°æ®é›†ç»Ÿè®¡ä¿¡æ¯"""
    
    # æ•°æ®æ–‡ä»¶è·¯å¾„
    train_path = "data/csv/train_correct.csv"
    test_path = "data/csv/test_correct.csv"
    
    print("=== æ•°æ®é›†ç»Ÿè®¡åˆ†æ ===\n")
    
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(train_path):
        print(f"âŒ è®­ç»ƒé›†æ–‡ä»¶ä¸å­˜åœ¨: {train_path}")
        return
    if not os.path.exists(test_path):
        print(f"âŒ æµ‹è¯•é›†æ–‡ä»¶ä¸å­˜åœ¨: {test_path}")
        return
    
    # åŠ è½½æ•°æ®é›†
    print("ğŸ“Š åŠ è½½æ•°æ®é›†...")
    train_df = pd.read_csv(train_path)
    test_df = pd.read_csv(test_path)
    
    print(f"âœ… è®­ç»ƒé›†åŠ è½½å®Œæˆ: {len(train_df)} æ¡è®°å½•")
    print(f"âœ… æµ‹è¯•é›†åŠ è½½å®Œæˆ: {len(test_df)} æ¡è®°å½•\n")
    
    # åˆ†æè®­ç»ƒé›†
    print("ğŸ” è®­ç»ƒé›†ç»Ÿè®¡ä¿¡æ¯:")
    analyze_single_dataset(train_df, "è®­ç»ƒé›†")
    
    print("\n" + "="*50 + "\n")
    
    # åˆ†ææµ‹è¯•é›†
    print("ğŸ” æµ‹è¯•é›†ç»Ÿè®¡ä¿¡æ¯:")
    analyze_single_dataset(test_df, "æµ‹è¯•é›†")
    
    return train_df, test_df

def analyze_single_dataset(df, dataset_name):
    """åˆ†æå•ä¸ªæ•°æ®é›†çš„ç»Ÿè®¡ä¿¡æ¯"""
    
    # åŸºæœ¬ç»Ÿè®¡
    total_pairs = len(df)
    positive_pairs = len(df[df['label'] == 1])
    negative_pairs = len(df[df['label'] == 0])
    
    print(f"ğŸ“ˆ {dataset_name}åŸºæœ¬ç»Ÿè®¡:")
    print(f"   æ€»è½¨è¿¹å¯¹æ•°: {total_pairs}")
    print(f"   æ­£æ ·æœ¬å¯¹æ•°: {positive_pairs} ({positive_pairs/total_pairs*100:.1f}%)")
    print(f"   è´Ÿæ ·æœ¬å¯¹æ•°: {negative_pairs} ({negative_pairs/total_pairs*100:.1f}%)")
    
    # åœºæ™¯ç»Ÿè®¡
    if 'scene_id' in df.columns:
        unique_scenes = df['scene_id'].nunique()
        scene_counts = df['scene_id'].value_counts().sort_index()
        
        print(f"\nğŸ¬ åœºæ™¯ç»Ÿè®¡:")
        print(f"   æ€»åœºæ™¯æ•°: {unique_scenes}")
        print(f"   æ¯åœºæ™¯è½¨è¿¹å¯¹æ•°èŒƒå›´: {scene_counts.min()} - {scene_counts.max()}")
        print(f"   å¹³å‡æ¯åœºæ™¯è½¨è¿¹å¯¹æ•°: {scene_counts.mean():.1f}")
        
        # æ˜¾ç¤ºå‰10ä¸ªåœºæ™¯çš„è½¨è¿¹å¯¹æ•°
        print(f"\n   å‰10ä¸ªåœºæ™¯çš„è½¨è¿¹å¯¹åˆ†å¸ƒ:")
        for scene_id, count in scene_counts.head(10).items():
            print(f"     åœºæ™¯ {scene_id}: {count} å¯¹")
    
    # è¿åŠ¨æ¨¡å¼ç»Ÿè®¡
    if 'motion_mode' in df.columns:
        motion_counts = df['motion_mode'].value_counts()
        
        print(f"\nğŸš€ è¿åŠ¨æ¨¡å¼ç»Ÿè®¡:")
        for mode, count in motion_counts.items():
            print(f"   {mode}: {count} å¯¹ ({count/total_pairs*100:.1f}%)")
    
    # ç›®æ ‡æ ‡å¿—ç»Ÿè®¡
    if 'old_target_flag' in df.columns and 'new_target_flag' in df.columns:
        old_targets = df['old_target_flag'].nunique()
        new_targets = df['new_target_flag'].nunique()
        
        print(f"\nğŸ¯ ç›®æ ‡ç»Ÿè®¡:")
        print(f"   Oldè½¨è¿¹å”¯ä¸€ç›®æ ‡æ•°: {old_targets}")
        print(f"   Newè½¨è¿¹å”¯ä¸€ç›®æ ‡æ•°: {new_targets}")
        
        # ç»Ÿè®¡æ¯ä¸ªåœºæ™¯ä¸­çš„ç›®æ ‡æ•°é‡
        if 'scene_id' in df.columns:
            scene_target_stats = []
            for scene_id in df['scene_id'].unique():
                scene_data = df[df['scene_id'] == scene_id]
                old_targets_in_scene = scene_data['old_target_flag'].nunique()
                new_targets_in_scene = scene_data['new_target_flag'].nunique()
                scene_target_stats.append({
                    'scene_id': scene_id,
                    'old_targets': old_targets_in_scene,
                    'new_targets': new_targets_in_scene,
                    'total_pairs': len(scene_data)
                })
            
            scene_target_df = pd.DataFrame(scene_target_stats)
            print(f"\n   åœºæ™¯ç›®æ ‡ç»Ÿè®¡:")
            print(f"     å¹³å‡æ¯åœºæ™¯Oldç›®æ ‡æ•°: {scene_target_df['old_targets'].mean():.1f}")
            print(f"     å¹³å‡æ¯åœºæ™¯Newç›®æ ‡æ•°: {scene_target_df['new_targets'].mean():.1f}")
            print(f"     ç›®æ ‡æ•°èŒƒå›´ (Old): {scene_target_df['old_targets'].min()} - {scene_target_df['old_targets'].max()}")
            print(f"     ç›®æ ‡æ•°èŒƒå›´ (New): {scene_target_df['new_targets'].min()} - {scene_target_df['new_targets'].max()}")

def get_trajectory_data(df, row_idx):
    """ä»æ•°æ®æ¡†ä¸­æå–è½¨è¿¹æ•°æ®"""
    row = df.iloc[row_idx]
    
    # æå–oldè½¨è¿¹
    old_traj = []
    new_traj = []
    
    for t in range(13):  # 13ä¸ªæ—¶é—´æ­¥
        old_point = [
            row[f'old_raw_x_{t}'],
            row[f'old_raw_y_{t}']
        ]
        new_point = [
            row[f'new_raw_x_{t}'],
            row[f'new_raw_y_{t}']
        ]
        old_traj.append(old_point)
        new_traj.append(new_point)
    
    return np.array(old_traj), np.array(new_traj)

def get_scene_trajectories(df, scene_id, max_pairs=None):
    """è·å–æŒ‡å®šåœºæ™¯çš„æ‰€æœ‰è½¨è¿¹å¯¹"""
    scene_data = df[df['scene_id'] == scene_id]
    
    if max_pairs:
        scene_data = scene_data.head(max_pairs)
    
    trajectories = []
    for idx in range(len(scene_data)):
        row = scene_data.iloc[idx]
        old_traj, new_traj = get_trajectory_data(pd.DataFrame([row]), 0)
        
        trajectories.append({
            'old_trajectory': old_traj,
            'new_trajectory': new_traj,
            'label': row['label'],
            'old_target_flag': row['old_target_flag'],
            'new_target_flag': row['new_target_flag'],
            'motion_mode': row.get('motion_mode', 'unknown')
        })
    
    return trajectories

if __name__ == "__main__":
    # è¿è¡Œç»Ÿè®¡åˆ†æ
    train_df, test_df = analyze_dataset_statistics()
    
    print("\n" + "="*60)
    print("ğŸ“‹ æ•°æ®é›†ç»Ÿè®¡åˆ†æå®Œæˆ!")
    print("="*60)